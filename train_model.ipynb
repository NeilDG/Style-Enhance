{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from metrics import MultiScaleSSIM\n",
    "from metrics import tf_ms_ssim\n",
    "\n",
    "import time\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import models as models\n",
    "from load_dataset import load_test_data, load_train_data\n",
    "import utils\n",
    "import vgg\n",
    "import loss\n",
    "\n",
    "import os, shutil\n",
    "import sys\n",
    "from os import environ\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'images/'\n",
    "use_gpu = \"true\"\n",
    "vgg_dir = \"vgg_pretrained/imagenet-vgg-verydeep-19.mat\"\n",
    "\n",
    "num_epochs = int(environ.get('epochs', '10'))\n",
    "test_size = int(environ.get('test_size', '200'))\n",
    "batch_size = int(environ.get('batch_size', '16'))\n",
    "load_step = int(environ.get('load_step', '1000'))\n",
    "\n",
    "#set to -1 to use all training patches\n",
    "num_train_data = int(environ.get('train_data', '-1'))\n",
    "target = environ.get('target', 'iPhone8')\n",
    "source = environ.get('source', 'Nova2i')\n",
    "learning_rate_gen = float(environ.get('lr_g', '0.0001'))\n",
    "learning_rate_disc = float(environ.get('lr_d', '0.0004'))\n",
    "beta1 = float(environ.get('beta', '0.9'))\n",
    "num_train_iters = int(environ.get('iterations', '1000'))\n",
    "num_resnet = int(environ.get('resnet', '16'))\n",
    "g_iters = int(environ.get('g_iters', '1'))\n",
    "d_iters = int(environ.get('d_iters', '1'))\n",
    "pixel = environ.get('pixel', 'L2')\n",
    "VGG_LAYER = environ.get('vgg_layer', 'conv5_4')\n",
    "gan = environ.get('gan', 'hinge')\n",
    "model = environ.get('model', 'styleenhance')\n",
    "start_iter = int(environ.get('start_iter', '0'))\n",
    "#use when initializing using a pre-trained model. \"same\" is used if the model have a same filename\n",
    "init = environ.get('init', 'same')\n",
    "\n",
    "#set to 1 if not label smoothing\n",
    "label_smoothing = 1\n",
    "    \n",
    "if(environ.get('use_sn', 'True') == 'True'):\n",
    "    use_sn = True\n",
    "    print(\"Spectral Norm\")\n",
    "else:\n",
    "    use_sn = False\n",
    "    \n",
    "phone = source\n",
    "\n",
    "hqFolder = os.getcwd() + \"/images/\" + target + \"/\"\n",
    "lqFolder = os.getcwd() + \"/images/\" + source + \"/\"\n",
    "registeredFolder = \"registered/\"\n",
    "hqPatches = hqFolder + \"train_patches/\"\n",
    "lqPatches = lqFolder + \"train_patches/\"\n",
    "hqTestPatches = hqFolder + \"test_patches/\"\n",
    "lqTestPatches = lqFolder + \"test_patches/\"\n",
    "\n",
    "\n",
    "total_train_data = len([name for name in os.listdir(lqPatches) if os.path.isfile(os.path.join(lqPatches, name))])\n",
    "\n",
    "if(num_train_data == -1):\n",
    "    num_train_data = total_train_data\n",
    "iters_per_epoch = math.floor(num_train_data / batch_size)\n",
    "if(num_epochs != 0):\n",
    "    num_train_iters = int(num_epochs * iters_per_epoch)\n",
    "if(load_step == -1):\n",
    "    load_step = iters_per_epoch\n",
    "train_size = int(load_step * batch_size)\n",
    "load_per_epoch = int(math.ceil(num_train_data / train_size))\n",
    "if(train_size > num_train_data):\n",
    "    load_per_epoch = 1\n",
    "\n",
    "print(\"Train Data: \" + str(num_train_data))\n",
    "print(\"Train Size: \" + str(train_size))\n",
    "print(\"Batch Size: \" + str(batch_size))\n",
    "print(\"Load Iterations: \" + str(load_step))\n",
    "print(\"Number of Epochs:\" + str(num_train_iters / iters_per_epoch))\n",
    "print(\"Iterations per Epoch: \" + str(iters_per_epoch))\n",
    "print(\"Train data loading per Epoch: \" + str(load_per_epoch))\n",
    "print(\"Number of Iterations: \" + str(num_train_iters)) \n",
    "\n",
    "w_gan = float(environ.get('w_gan', '1000'))\n",
    "w_pixel = float(environ.get('w_pixel', '1'))\n",
    "w_perceptual = float(environ.get('w_perceptual', '0.5'))\n",
    "\n",
    "config = tf.ConfigProto(device_count={'GPU': 0}) if use_gpu == \"false\" else None\n",
    "\n",
    "PATCH_WIDTH = int(environ.get('width', '96'))\n",
    "PATCH_HEIGHT = int(environ.get('height', '96'))\n",
    "PATCH_SIZE = PATCH_WIDTH * PATCH_HEIGHT * 3\n",
    "\n",
    "print(\"GAN Loss: \" + gan)\n",
    "print(\"Model Name: \" + model)\n",
    "print(\"Target: \" + target)\n",
    "print(\"Source: \" + source)  \n",
    "\n",
    "gpu = environ.get('gpu', '0')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "if(init == \"same\"):\n",
    "    init = model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_idx = 0\n",
    "\n",
    "print(\"Loading test data...\")\n",
    "test_data, test_target = load_test_data(phone, dataset_dir, test_size, PATCH_SIZE, PATCH_WIDTH, target)\n",
    "print(\"Test data was loaded\\n\")\n",
    "\n",
    "print(\"Loading training data...\")\n",
    "train_data, train_target, reload = load_train_data(phone, dataset_dir, train_size, PATCH_SIZE, PATCH_WIDTH, target, data_idx % load_per_epoch, train_data_size=num_train_data)\n",
    "print(\"Training data was loaded\\n\")\n",
    "\n",
    "data_idx += 1\n",
    "\n",
    "#if the entire dataset as been loaded\n",
    "if(not reload):\n",
    "    print(\"Reload\")\n",
    "    train_size = train_data.shape[0]\n",
    "\n",
    "TEST_SIZE = test_data.shape[0]\n",
    "num_test_batches = int(test_data.shape[0] / batch_size)\n",
    "num_train_batches = int(math.floor(train_data.shape[0] / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "with tf.Graph().as_default() as graph:\n",
    "    with tf.Session(config=config) as sess:\n",
    "        lq_ = tf.placeholder(tf.float32, [None, PATCH_HEIGHT, PATCH_WIDTH, 3])\n",
    "        lq_image = lq_\n",
    "        hq_ = tf.placeholder(tf.float32, [None, PATCH_HEIGHT, PATCH_WIDTH, 3])\n",
    "        hq_image = hq_\n",
    "        \n",
    "        #print(hq_image)\n",
    "        hq_image = hq_image * 2.0\n",
    "        hq_image = hq_image - 1.0\n",
    "        lq_image = lq_image * 2.0\n",
    "        lq_image = lq_image - 1.0\n",
    "        \n",
    "        #real_image = tf.identity(hq_image)\n",
    "        #real_image = real_image * 2\n",
    "        #real_image = real_image - 1\n",
    "        \n",
    "        is_train = tf.placeholder(tf.int16)\n",
    "\n",
    "        if(is_train == 1):\n",
    "            gen_hq = models.generator(lq_image, hq_image, \"_lq\", n_resnet=num_resnet, isTraining=True, use_sn=False)\n",
    "        else:\n",
    "            gen_hq = models.generator(lq_image, hq_image, \"_lq\", n_resnet=num_resnet, isTraining=False, use_sn=False)\n",
    "            \n",
    "        #Adversarial Loss\n",
    "        _, logits_disc, logits_disc_pred = models.discriminator(tf.concat([hq_image, gen_hq], 0), \"_ch\", use_sn=use_sn)\n",
    "        logits_hq, logits_en = tf.split(logits_disc, num_or_size_splits=2, axis=0)\n",
    "        logits_hq_pred, logits_en_pred = tf.split(logits_disc_pred, num_or_size_splits=2, axis=0)\n",
    "        \n",
    "        discrim_accuracy = tf.reduce_mean(logits_hq_pred + (1-logits_en_pred)) / 2\n",
    "        accuracy_real = tf.reduce_mean(logits_hq)\n",
    "        accuracy_fake = tf.reduce_mean(logits_en)\n",
    "\n",
    "        loss_gen, loss_discrim, gan = loss.generator_loss(gan, gen_hq, hq_image, logits_hq, logits_en, label_smoothing, batch_size)\n",
    "        \n",
    "        #Pixel Loss\n",
    "        loss_pixel = loss.pixel_loss(pixel, hq_image, gen_hq, batch_size)\n",
    "\n",
    "        #Perceptual Loss     \n",
    "        gen_hq_vgg = vgg.net(vgg_dir, vgg.preprocess((gen_hq + 1) * 2 * 255))\n",
    "        hq_vgg = vgg.net(vgg_dir, vgg.preprocess((hq_image + 1) * 2 * 255))\n",
    "        \n",
    "        loss_perceptual = loss.perceptual_loss(gen_hq_vgg, hq_vgg, VGG_LAYER, pixel, batch_size)\n",
    "        \n",
    "        #Image quality metrics\n",
    "        loss_mse = tf.reduce_sum(tf.pow(hq_image - gen_hq, 2))/(PATCH_SIZE * batch_size)\n",
    "        loss_psnr = -(20 * utils.log10(1.0 / tf.sqrt(loss_mse)))\n",
    "        loss_ssim = 1 - tf.reduce_mean(tf.image.ssim(hq_image, gen_hq, 1))\n",
    "\n",
    "        #Multi-term Loss\n",
    "        loss_final = w_perceptual * loss_perceptual + w_pixel * loss_pixel + w_gan * loss_gen\n",
    "        \n",
    "        #Optimizer\n",
    "        optimizer_gen = tf.train.AdamOptimizer(learning_rate_gen, beta1=beta1)\n",
    "        optimizer_disc = tf.train.AdamOptimizer(learning_rate_disc, beta1=beta1)\n",
    "        \n",
    "        generator_vars = [v for v in tf.global_variables() if \"generator\" in v.name]\n",
    "        discriminator_vars = [v for v in tf.global_variables() if \"discriminator\" in v.name]\n",
    "        \n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            train_step_gen = optimizer_gen.minimize(loss_final, var_list=generator_vars)\n",
    "            train_step_disc = optimizer_disc.minimize(loss_discrim, var_list=discriminator_vars)\n",
    "        \n",
    "        with tf.name_scope(\"pixel_loss\") as scope:\n",
    "            tf.summary.scalar('pixel_Loss', loss_pixel)\n",
    "            \n",
    "        with tf.name_scope(\"adversarial_loss\") as scope:\n",
    "            tf.summary.scalar('Discriminator_Loss', loss_discrim)\n",
    "            tf.summary.scalar('Discriminator_Accuracy', discrim_accuracy)\n",
    "            tf.summary.scalar('Generator_Loss', loss_gen)\n",
    "            \n",
    "        with tf.name_scope(\"perceptual_loss\") as scope:\n",
    "            tf.summary.scalar('VGG_Loss', loss_perceptual)\n",
    "        \n",
    "        with tf.name_scope(\"psnr_mse\") as scope:\n",
    "            tf.summary.scalar('PSNR', loss_psnr)\n",
    "            tf.summary.scalar('MSE', loss_mse)\n",
    "            tf.summary.scalar('SSIM', loss_ssim)\n",
    "            \n",
    "        with tf.name_scope(\"final_loss\") as scope:\n",
    "            tf.summary.scalar('Final_Loss', loss_final)\n",
    "            tf.summary.scalar('Adv_Loss', w_gan * loss_gen)\n",
    "            tf.summary.scalar('Pixel_Loss', w_pixel * loss_pixel)\n",
    "            tf.summary.scalar('Perceptual_Loss', w_perceptual * loss_perceptual)\n",
    "        \n",
    "        if(start_iter > 0):\n",
    "            print(\"Loading variables\")\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess, 'models/' + str(phone) + \"_\"  + init + '_iteration_' + str(start_iter) + \".ckpt\")\n",
    "            start_iter += 1\n",
    "            print(start_iter)\n",
    "            start_iter = int(start_iter)\n",
    "        else:\n",
    "            print('Initializing variables')\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "        print(\"Time elapsed: \" + str(time.time() - start))\n",
    "        print('Training network')  \n",
    "        \n",
    "        saver = tf.train.Saver(max_to_keep=3)\n",
    "        epoch_saver = tf.train.Saver()\n",
    "        gen_saver = tf.train.Saver(var_list=generator_vars, max_to_keep=1)\n",
    "        \n",
    "        train_loss_gen = 0.0\n",
    "        train_loss_disc = 0.0\n",
    "        train_acc_discrim = 0.0\n",
    "        crops_i = random.sample(range(TEST_SIZE), 5)\n",
    "        test_crops = test_data[crops_i, :]\n",
    "        test_gt = test_target[crops_i, :]\n",
    "\n",
    "        logs = open('models/' + phone + '.txt', \"w+\")\n",
    "        logs.close()\n",
    "        \n",
    "        merge = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter( os.path.join(os.getcwd(),'tensorboard/others/train_' + phone + '_' + model + model), tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter( os.path.join(os.getcwd(),'tensorboard/others/test_' + phone + '_' + model + model))\n",
    "        epoch_writer = tf.summary.FileWriter( os.path.join(os.getcwd(),'tensorboard/others/epoch_' + phone + '_' + model + model))\n",
    "        epoch_test_writer = tf.summary.FileWriter( os.path.join(os.getcwd(),'tensorboard/others/epoch_test_' + phone + '_' + model + model))\n",
    "        \n",
    "        run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "        \n",
    "        for i in range(start_iter, num_train_iters):\n",
    "            print(i)\n",
    "            iter_start = time.time()\n",
    "            print(\"Training \" + str((i + 1) * batch_size) + \"/\" + str(total_train_data))\n",
    "            \n",
    "            be = (num_train_batches - 1) * batch_size\n",
    "            en = num_train_batches * batch_size\n",
    "            idx_train = range(be,en)\n",
    "            lq_images = train_data[idx_train]\n",
    "            hq_images = train_target[idx_train]\n",
    "            \n",
    "            num_train_batches -= 1\n",
    "            \n",
    "            for j in range(g_iters):\n",
    "                # train generator\n",
    "                [summary, loss_temp, acc, temp] = sess.run([merge, loss_final, loss_gen, train_step_gen],\n",
    "                                                feed_dict={lq_: lq_images, hq_: hq_images, is_train: 1}, options = run_options)\n",
    "                \n",
    "                train_loss_gen += loss_temp / (load_step * g_iters)\n",
    "            for j in range(d_iters):\n",
    "                # train discriminator\n",
    "                [summary, accuracy_temp, loss_temp, temp] = sess.run([merge, discrim_accuracy, loss_discrim, train_step_disc],\n",
    "                                                feed_dict={lq_:lq_images, hq_:hq_images, is_train: 1}, options = run_options)\n",
    "                train_loss_disc += loss_temp / (load_step * d_iters)\n",
    "                train_acc_discrim += accuracy_temp / (load_step * d_iters)\n",
    "            train_writer.add_summary(summary, i)\n",
    "            if (i % iters_per_epoch == 0 or i == num_train_iters-1):\n",
    "                epoch_writer.add_summary(summary, math.ceil(i / iters_per_epoch))\n",
    "                \n",
    "            print(\"Iteration Time Elapsed: \" + str(time.time() - iter_start))\n",
    "                \n",
    "            if((i + 1) % load_step == 0 or i % iters_per_epoch == 0 or i == num_train_iters-1):\n",
    "\n",
    "                # test generator and discriminator CNNs\n",
    "                test_losses_gen = np.zeros((1, 9))\n",
    "                test_accuracy_disc = 0.0\n",
    "\n",
    "                for j in range(num_test_batches):\n",
    "\n",
    "                    be = j * batch_size\n",
    "                    en = (j+1) * batch_size\n",
    "\n",
    "                    lq_images = test_data[be:en]\n",
    "                    hq_images = test_target[be:en]\n",
    "\n",
    "                    [summary, accuracy_disc, losses] = sess.run([merge, discrim_accuracy, \\\n",
    "                                 [loss_final, loss_gen, loss_pixel, loss_perceptual, loss_discrim, accuracy_real, accuracy_fake, loss_psnr, loss_ssim]], \\\n",
    "                                    feed_dict={lq_: lq_images, hq_: hq_images, is_train: 0})\n",
    "                    test_writer.add_summary(summary, i)\n",
    "                    \n",
    "                    \n",
    "                    if (i % iters_per_epoch == 0 or i == num_train_iters-1):\n",
    "                        epoch_test_writer.add_summary(summary, math.ceil(i / iters_per_epoch))\n",
    "\n",
    "                    test_losses_gen += np.asarray(losses) / num_test_batches\n",
    "                    test_accuracy_disc += accuracy_disc / num_test_batches\n",
    "\n",
    "                logs_disc = \"Iteration %d, %s | discriminator accuracy | train: %.4g, test: %.4g | discriminator loss | train: %.4g test: %.4g real: %.4g fake: %.4g\" % \\\n",
    "                  (i, phone, train_acc_discrim, test_accuracy_disc, train_loss_disc, test_losses_gen[0][4], test_losses_gen[0][5], test_losses_gen[0][6])\n",
    "                logs_gen = \"generator losses | train: %.4g, test: %.4g | gen: %.4g, pixel: %.4g vgg: %.4g PSNR: %.4g SSIM: %.4g\\n\" % \\\n",
    "                  (train_loss_gen, test_losses_gen[0][0], test_losses_gen[0][1], test_losses_gen[0][2], test_losses_gen[0][3], test_losses_gen[0][7], test_losses_gen[0][8])\n",
    "                print(logs_disc)\n",
    "                print(logs_gen)\n",
    "\n",
    "                # save the results to log file\n",
    "\n",
    "                logs = open('models/' + phone + model + '.txt', \"a\")\n",
    "                \n",
    "                if(i == 0):\n",
    "                    logs.write(\"\\nGAN loss: \" + str(gan))\n",
    "                    logs.write(\"\\nTrain Data: \" + str(num_train_data))\n",
    "                    logs.write(\"\\nBatch Size: \" + str(batch_size))\n",
    "                    logs.write(\"\\nNumber of Epochs:\" + str(num_train_iters / iters_per_epoch))\n",
    "                    logs.write(\"\\nIterations: \" + str(num_train_iters))\n",
    "                    logs.write(\"\\nIterations per Epoch: \" + str(iters_per_epoch))\n",
    "                    logs.write(\"\\nTrain Size: \" + str(train_size))\n",
    "                    logs.write(\"\\nTest Data Size: \" + str(test_size))\n",
    "                    logs.write(\"\\nLoad Iteration: \" + str(load_step))\n",
    "                    logs.write(\"\\nLearning Rate (Gen): \" + str(learning_rate_gen))\n",
    "                    logs.write(\"\\nLearning Rate (Disc): \" + str(learning_rate_disc))\n",
    "                    logs.write(\"\\nStart Iteration: \" + str(start_iter))\n",
    "                    logs.write(\"\\nInitialization: \" + init)   \n",
    "                    logs.write('\\n')\n",
    "                    logs.write('\\n')\n",
    "                    \n",
    "                gen_hq_crops = sess.run(gen_hq, feed_dict={lq_: test_crops, hq_: hq_images, is_train: 0}, options = run_options)\n",
    "                if ((i + 1) % load_step == 0 or i == num_train_iters-1):\n",
    "                    logs.write(logs_gen)\n",
    "                    logs.write(logs_disc)\n",
    "                    logs.write('\\n')\n",
    "                \n",
    "                logs.close()\n",
    "                idx = 0\n",
    "                for crop in gen_hq_crops:\n",
    "                    crop = (crop + 1) / 2\n",
    "                    before_after = np.hstack((np.reshape(test_crops[idx], [PATCH_HEIGHT, PATCH_WIDTH, 3]), crop, (np.reshape(test_gt[idx], [PATCH_HEIGHT, PATCH_WIDTH, 3]))))\n",
    "                    plt.imsave('validation_results/' + str(phone) + model + \"_\" + str(idx) + '_iteration_' + str(i) + '.jpg', before_after)\n",
    "                    idx += 1\n",
    "                \n",
    "                if((i + 1) % load_step == 0): \n",
    "                    train_loss_gen = 0.0\n",
    "                    train_loss_disc = 0.0\n",
    "                    train_acc_discrim = 0.0\n",
    "\n",
    "                # save the model that corresponds to the current iteration\n",
    "                if(i % iters_per_epoch == 0 and i != 0):\n",
    "                    epoch_saver.save(sess, 'models/' + str(phone) + \"_\"  + model + '_epoch_' + str(int(math.floor(i / iters_per_epoch))) + '.ckpt', write_meta_graph=False)\n",
    "                if((i + 1) % load_step == 0 or i == num_train_iters-1):\n",
    "                    saver.save(sess, 'models/' + str(phone) + \"_\"  + model + '_iteration_' + str(i) + '.ckpt', write_meta_graph=False)\n",
    "                print(\"Loading new batch...\")\n",
    "                \n",
    "            # reload a next batch of training data\n",
    "            if(reload and num_train_batches == 0):\n",
    "                print(\"Loading \" + str(i))\n",
    "                del train_data\n",
    "                del train_target\n",
    "                print((data_idx % load_per_epoch) * train_size)\n",
    "                print(((data_idx % load_per_epoch) + 1) * train_size)\n",
    "                train_data, train_target, reload = load_train_data(phone, dataset_dir, train_size, PATCH_SIZE, PATCH_WIDTH, target, data_idx % load_per_epoch, train_data_size=num_train_data)\n",
    "                data_idx += 1\n",
    "            \n",
    "            if(num_train_batches == 0):\n",
    "                num_train_batches = int(math.floor(train_data.shape[0] / batch_size))\n",
    "                print(num_train_batches)\n",
    "                indices = np.arange(train_data.shape[0])\n",
    "                np.random.shuffle(indices)\n",
    "\n",
    "                train_data = train_data[indices]\n",
    "                train_target = train_target[indices]\n",
    "                \n",
    "                \n",
    "            print(\"New Batch Loaded...\")\n",
    "            print(\"Time Elapsed: \" + str(time.time() - start))\n",
    "                        \n",
    "        print(\"Total Time Elapsed: \" + str(time.time() - start))\n",
    "        \n",
    "        logs = open('models/' + phone + model + '.txt', \"a\")\n",
    "        logs.write(\"\\n\\nTotal Time Elapsed: \" + str(time.time() - start))\n",
    "        logs.write('\\n')\n",
    "        logs.close()\n",
    "\n",
    "        train_writer.close()\n",
    "        test_writer.close()\n",
    "        epoch_writer.close()\n",
    "        epoch_test_writer.close()\n",
    "    \n",
    "                \n",
    "                    \n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
