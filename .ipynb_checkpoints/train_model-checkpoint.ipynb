{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from metrics import MultiScaleSSIM\n",
    "from metrics import tf_ms_ssim\n",
    "\n",
    "import time\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import models as models\n",
    "from load_dataset import load_test_data, load_train_data\n",
    "import utils\n",
    "import vgg\n",
    "import loss\n",
    "\n",
    "import os, shutil\n",
    "import sys\n",
    "from os import environ\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectral Norm\n",
      "Train Data: 43585\n",
      "Train Size: 16\n",
      "Batch Size: 16\n",
      "Load Iterations: 1\n",
      "Number of Epochs:10.0\n",
      "Iterations per Epoch: 2724\n",
      "Train data loading per Epoch: 2725\n",
      "Number of Iterations: 27240\n",
      "GAN Loss: hinge\n",
      "Model Name: styleenhance\n",
      "Target: iPhone8\n",
      "Source: Nova2i\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = 'images/'\n",
    "use_gpu = \"true\"\n",
    "vgg_dir = \"vgg_pretrained/imagenet-vgg-verydeep-19.mat\"\n",
    "\n",
    "num_epochs = int(environ.get('epochs', '10'))\n",
    "test_size = int(environ.get('test_size', '200'))\n",
    "batch_size = int(environ.get('batch_size', '16'))\n",
    "load_step = int(environ.get('load_step', '1000'))\n",
    "\n",
    "#set to -1 to use all training patches\n",
    "num_train_data = int(environ.get('train_data', '-1'))\n",
    "target = environ.get('target', 'iPhone8')\n",
    "source = environ.get('source', 'Nova2i')\n",
    "learning_rate_gen = float(environ.get('lr_g', '0.0001'))\n",
    "learning_rate_disc = float(environ.get('lr_d', '0.0004'))\n",
    "beta1 = float(environ.get('beta', '0.9'))\n",
    "num_train_iters = int(environ.get('iterations', '1000'))\n",
    "num_resnet = int(environ.get('resnet', '16'))\n",
    "g_iters = int(environ.get('g_iters', '1'))\n",
    "d_iters = int(environ.get('d_iters', '1'))\n",
    "pixel = environ.get('pixel', 'L2')\n",
    "VGG_LAYER = environ.get('vgg_layer', 'conv5_4')\n",
    "gan = environ.get('gan', 'hinge')\n",
    "model = environ.get('model', 'styleenhance')\n",
    "start_iter = int(environ.get('start_iter', '0'))\n",
    "#use when initializing using a pre-trained model. \"same\" is used if the model have a same filename\n",
    "init = environ.get('init', 'same')\n",
    "\n",
    "#set to 1 if not label smoothing\n",
    "label_smoothing = 1\n",
    "    \n",
    "if(environ.get('use_sn', 'True') == 'True'):\n",
    "    use_sn = True\n",
    "    print(\"Spectral Norm\")\n",
    "else:\n",
    "    use_sn = False\n",
    "    \n",
    "phone = source\n",
    "\n",
    "hqFolder = os.getcwd() + \"/images/\" + target + \"/\"\n",
    "lqFolder = os.getcwd() + \"/images/\" + source + \"/\"\n",
    "registeredFolder = \"registered/\"\n",
    "hqPatches = hqFolder + \"train_patches/\"\n",
    "lqPatches = lqFolder + \"train_patches/\"\n",
    "hqTestPatches = hqFolder + \"test_patches/\"\n",
    "lqTestPatches = lqFolder + \"test_patches/\"\n",
    "\n",
    "\n",
    "total_train_data = len([name for name in os.listdir(lqPatches) if os.path.isfile(os.path.join(lqPatches, name))])\n",
    "\n",
    "if(num_train_data == -1):\n",
    "    num_train_data = total_train_data\n",
    "iters_per_epoch = math.floor(num_train_data / batch_size)\n",
    "if(num_epochs != 0):\n",
    "    num_train_iters = int(num_epochs * iters_per_epoch)\n",
    "if(load_step == -1):\n",
    "    load_step = iters_per_epoch\n",
    "train_size = int(load_step * batch_size)\n",
    "load_per_epoch = int(math.ceil(num_train_data / train_size))\n",
    "if(train_size > num_train_data):\n",
    "    load_per_epoch = 1\n",
    "\n",
    "print(\"Train Data: \" + str(num_train_data))\n",
    "print(\"Train Size: \" + str(train_size))\n",
    "print(\"Batch Size: \" + str(batch_size))\n",
    "print(\"Load Iterations: \" + str(load_step))\n",
    "print(\"Number of Epochs:\" + str(num_train_iters / iters_per_epoch))\n",
    "print(\"Iterations per Epoch: \" + str(iters_per_epoch))\n",
    "print(\"Train data loading per Epoch: \" + str(load_per_epoch))\n",
    "print(\"Number of Iterations: \" + str(num_train_iters)) \n",
    "\n",
    "w_gan = float(environ.get('w_gan', '1000'))\n",
    "w_pixel = float(environ.get('w_pixel', '1'))\n",
    "w_perceptual = float(environ.get('w_perceptual', '0.5'))\n",
    "\n",
    "config = tf.ConfigProto(device_count={'GPU': 0}) if use_gpu == \"false\" else None\n",
    "\n",
    "PATCH_WIDTH = int(environ.get('width', '96'))\n",
    "PATCH_HEIGHT = int(environ.get('height', '96'))\n",
    "PATCH_SIZE = PATCH_WIDTH * PATCH_HEIGHT * 3\n",
    "\n",
    "print(\"GAN Loss: \" + gan)\n",
    "print(\"Model Name: \" + model)\n",
    "print(\"Target: \" + target)\n",
    "print(\"Source: \" + source)  \n",
    "\n",
    "gpu = environ.get('gpu', '0')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "if(init == \"same\"):\n",
    "    init = model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n",
      "Test data was loaded\n",
      "\n",
      "Loading training data...\n",
      "16\n",
      "Training data was loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_idx = 0\n",
    "\n",
    "print(\"Loading test data...\")\n",
    "test_data, test_target = load_test_data(phone, dataset_dir, test_size, PATCH_SIZE, PATCH_WIDTH, target)\n",
    "print(\"Test data was loaded\\n\")\n",
    "\n",
    "print(\"Loading training data...\")\n",
    "train_data, train_target, reload = load_train_data(phone, dataset_dir, train_size, PATCH_SIZE, PATCH_WIDTH, target, data_idx % load_per_epoch, train_data_size=num_train_data)\n",
    "print(\"Training data was loaded\\n\")\n",
    "\n",
    "data_idx += 1\n",
    "\n",
    "#if the entire dataset as been loaded\n",
    "if(not reload):\n",
    "    print(\"Reload\")\n",
    "    train_size = train_data.shape[0]\n",
    "\n",
    "TEST_SIZE = test_data.shape[0]\n",
    "num_test_batches = int(test_data.shape[0] / batch_size)\n",
    "num_train_batches = int(math.floor(train_data.shape[0] / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator\n",
      "(?, 96, 96, 3)\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "(?, 96, 96, 64)\n",
      "Discriminator\n",
      "(?, 96, 96, 3)\n",
      "(?, 96, 96, 64)\n",
      "Batch Norm\n",
      "(?, 48, 48, 64)\n",
      "Batch Norm\n",
      "(?, 48, 48, 128)\n",
      "Batch Norm\n",
      "(?, 24, 24, 128)\n",
      "Batch Norm\n",
      "(?, 24, 24, 256)\n",
      "Batch Norm\n",
      "(?, 12, 12, 256)\n",
      "Batch Norm\n",
      "(?, 12, 12, 512)\n",
      "Batch Norm\n",
      "WARNING:tensorflow:From C:\\Users\\ERDT\\Documents\\MSCS Thesis Files\\Style-Enhance\\models.py:84: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "Initializing variables\n",
      "Time elapsed: 7.978379726409912\n",
      "Training network\n",
      "0\n",
      "Training 16/43585\n",
      "Iteration Time Elapsed: 20.760433673858643\n",
      "Iteration 0, Nova2i | discriminator accuracy | train: 0.5094, test: 0.9066 | discriminator loss | train: 2.315 test: 0.968 real: 24.31 fake: -11.68\n",
      "generator losses | train: 8257, test: 2.412e+04 | gen: 11.68, pixel: 5821 vgg: 1.324e+04 PSNR: -3.824 SSIM: 0.9625\n",
      "\n",
      "Loading new batch...\n",
      "Loading 0\n",
      "16\n",
      "32\n",
      "16\n",
      "1\n",
      "New Batch Loaded...\n",
      "Time Elapsed: 68.60568881034851\n",
      "1\n",
      "Training 32/43585\n",
      "Iteration Time Elapsed: 1.0312411785125732\n",
      "Iteration 1, Nova2i | discriminator accuracy | train: 0.8156, test: 0.9323 | discriminator loss | train: 6.392 test: 0.4713 real: 20.61 fake: -10.74\n",
      "generator losses | train: 2.341e+04, test: 2.394e+04 | gen: 10.74, pixel: 6004 vgg: 1.439e+04 PSNR: -3.709 SSIM: 0.8982\n",
      "\n",
      "Loading new batch...\n",
      "Loading 1\n",
      "32\n",
      "48\n",
      "16\n",
      "1\n",
      "New Batch Loaded...\n",
      "Time Elapsed: 91.64152383804321\n",
      "2\n",
      "Training 48/43585\n",
      "Iteration Time Elapsed: 1.040282964706421\n",
      "Iteration 2, Nova2i | discriminator accuracy | train: 0.9455, test: 0.9314 | discriminator loss | train: 0.2905 test: 1.168 real: 22.77 fake: -15.47\n",
      "generator losses | train: 1.495e+04, test: 2.891e+04 | gen: 15.47, pixel: 5785 vgg: 1.532e+04 PSNR: -3.878 SSIM: 0.8666\n",
      "\n",
      "Loading new batch...\n",
      "Loading 2\n",
      "48\n",
      "64\n",
      "16\n",
      "1\n",
      "New Batch Loaded...\n",
      "Time Elapsed: 103.97894048690796\n",
      "3\n",
      "Training 64/43585\n",
      "Iteration Time Elapsed: 1.0060935020446777\n",
      "Iteration 3, Nova2i | discriminator accuracy | train: 0.9982, test: 0.8029 | discriminator loss | train: 0 test: 4.965 real: 20.75 fake: -14.96\n",
      "generator losses | train: 2.626e+04, test: 2.83e+04 | gen: 14.96, pixel: 5468 vgg: 1.574e+04 PSNR: -4.129 SSIM: 0.8236\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Loading new batch...\n",
      "Loading 3\n",
      "64\n",
      "80\n",
      "16\n",
      "1\n",
      "New Batch Loaded...\n",
      "Time Elapsed: 118.57279205322266\n",
      "4\n",
      "Training 80/43585\n",
      "Iteration Time Elapsed: 1.0104148387908936\n",
      "Iteration 4, Nova2i | discriminator accuracy | train: 0.4948, test: 0.7928 | discriminator loss | train: 16.8 test: 6.869 real: 21.36 fake: -16.43\n",
      "generator losses | train: 2.351e+04, test: 2.953e+04 | gen: 16.43, pixel: 5185 vgg: 1.582e+04 PSNR: -4.361 SSIM: 0.7723\n",
      "\n",
      "Loading new batch...\n",
      "Loading 4\n",
      "80\n",
      "96\n",
      "16\n",
      "1\n",
      "New Batch Loaded...\n",
      "Time Elapsed: 131.25927257537842\n",
      "5\n",
      "Training 96/43585\n",
      "Iteration Time Elapsed: 1.0048282146453857\n",
      "Iteration 5, Nova2i | discriminator accuracy | train: 0.9353, test: 0.6784 | discriminator loss | train: 2.435 test: 14.64 real: 17.75 fake: -11.37\n",
      "generator losses | train: 3.531e+04, test: 2.418e+04 | gen: 11.37, pixel: 4893 vgg: 1.582e+04 PSNR: -4.607 SSIM: 0.7494\n",
      "\n",
      "Loading new batch...\n",
      "Loading 5\n",
      "96\n",
      "112\n",
      "16\n",
      "1\n",
      "New Batch Loaded...\n",
      "Time Elapsed: 143.14136028289795\n",
      "6\n",
      "Training 112/43585\n",
      "Iteration Time Elapsed: 1.0292744636535645\n",
      "Iteration 6, Nova2i | discriminator accuracy | train: 0.9895, test: 0.7297 | discriminator loss | train: 0.0121 test: 13.6 real: 19.87 fake: -16.69\n",
      "generator losses | train: 4.162e+04, test: 2.857e+04 | gen: 16.69, pixel: 4415 vgg: 1.494e+04 PSNR: -5.037 SSIM: 0.7547\n",
      "\n",
      "Loading new batch...\n",
      "Loading 6\n",
      "112\n",
      "128\n",
      "16\n",
      "1\n",
      "New Batch Loaded...\n",
      "Time Elapsed: 157.1652102470398\n",
      "7\n",
      "Training 128/43585\n",
      "Iteration Time Elapsed: 1.0092999935150146\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-863e3d142d0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    171\u001b[0m                     [summary, accuracy_disc, losses] = sess.run([merge, discrim_accuracy, \\\n\u001b[0;32m    172\u001b[0m                                  [loss_final, loss_gen, loss_pixel, loss_perceptual, loss_discrim, accuracy_real, accuracy_fake, loss_psnr, loss_ssim]], \\\n\u001b[1;32m--> 173\u001b[1;33m                                     feed_dict={lq_: lq_images, hq_: hq_images, is_train: 0})\n\u001b[0m\u001b[0;32m    174\u001b[0m                     \u001b[0mtest_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "with tf.Graph().as_default() as graph:\n",
    "    with tf.Session(config=config) as sess:\n",
    "        lq_ = tf.placeholder(tf.float32, [None, PATCH_HEIGHT, PATCH_WIDTH, 3])\n",
    "        lq_image = lq_\n",
    "        hq_ = tf.placeholder(tf.float32, [None, PATCH_HEIGHT, PATCH_WIDTH, 3])\n",
    "        hq_image = hq_\n",
    "        \n",
    "        #print(hq_image)\n",
    "        hq_image = hq_image * 2.0\n",
    "        hq_image = hq_image - 1.0\n",
    "        lq_image = lq_image * 2.0\n",
    "        lq_image = lq_image - 1.0\n",
    "        \n",
    "        #real_image = tf.identity(hq_image)\n",
    "        #real_image = real_image * 2\n",
    "        #real_image = real_image - 1\n",
    "        \n",
    "        is_train = tf.placeholder(tf.int16)\n",
    "\n",
    "        if(is_train == 1):\n",
    "            gen_hq = models.generator(lq_image, hq_image, \"_lq\", n_resnet=num_resnet, isTraining=True, use_sn=False)\n",
    "        else:\n",
    "            gen_hq = models.generator(lq_image, hq_image, \"_lq\", n_resnet=num_resnet, isTraining=False, use_sn=False)\n",
    "            \n",
    "        #Adversarial Loss\n",
    "        _, logits_disc, logits_disc_pred = models.discriminator(tf.concat([hq_image, gen_hq], 0), \"_ch\", use_sn=use_sn)\n",
    "        logits_hq, logits_en = tf.split(logits_disc, num_or_size_splits=2, axis=0)\n",
    "        logits_hq_pred, logits_en_pred = tf.split(logits_disc_pred, num_or_size_splits=2, axis=0)\n",
    "        \n",
    "        discrim_accuracy = tf.reduce_mean(logits_hq_pred + (1-logits_en_pred)) / 2\n",
    "        accuracy_real = tf.reduce_mean(logits_hq)\n",
    "        accuracy_fake = tf.reduce_mean(logits_en)\n",
    "\n",
    "        loss_gen, loss_discrim, gan = loss.generator_loss(gan, gen_hq, hq_image, logits_hq, logits_en, label_smoothing, batch_size)\n",
    "        \n",
    "        #Pixel Loss\n",
    "        loss_pixel = loss.pixel_loss(pixel, hq_image, gen_hq, batch_size)\n",
    "\n",
    "        #Perceptual Loss     \n",
    "        gen_hq_vgg = vgg.net(vgg_dir, vgg.preprocess((gen_hq + 1) * 2 * 255))\n",
    "        hq_vgg = vgg.net(vgg_dir, vgg.preprocess((hq_image + 1) * 2 * 255))\n",
    "        \n",
    "        loss_perceptual = loss.perceptual_loss(gen_hq_vgg, hq_vgg, VGG_LAYER, pixel, batch_size)\n",
    "        \n",
    "        #Image quality metrics\n",
    "        loss_mse = tf.reduce_sum(tf.pow(hq_image - gen_hq, 2))/(PATCH_SIZE * batch_size)\n",
    "        loss_psnr = -(20 * utils.log10(1.0 / tf.sqrt(loss_mse)))\n",
    "        loss_ssim = 1 - tf.reduce_mean(tf.image.ssim(hq_image, gen_hq, 1))\n",
    "\n",
    "        #Multi-term Loss\n",
    "        loss_final = w_perceptual * loss_perceptual + w_pixel * loss_pixel + w_gan * loss_gen\n",
    "        \n",
    "        #Optimizer\n",
    "        optimizer_gen = tf.train.AdamOptimizer(learning_rate_gen, beta1=beta1)\n",
    "        optimizer_disc = tf.train.AdamOptimizer(learning_rate_disc, beta1=beta1)\n",
    "        \n",
    "        generator_vars = [v for v in tf.global_variables() if \"generator\" in v.name]\n",
    "        discriminator_vars = [v for v in tf.global_variables() if \"discriminator\" in v.name]\n",
    "        \n",
    "        with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "            train_step_gen = optimizer_gen.minimize(loss_final, var_list=generator_vars)\n",
    "            train_step_disc = optimizer_disc.minimize(loss_discrim, var_list=discriminator_vars)\n",
    "        \n",
    "        with tf.name_scope(\"pixel_loss\") as scope:\n",
    "            tf.summary.scalar('pixel_Loss', loss_pixel)\n",
    "            \n",
    "        with tf.name_scope(\"adversarial_loss\") as scope:\n",
    "            tf.summary.scalar('Discriminator_Loss', loss_discrim)\n",
    "            tf.summary.scalar('Discriminator_Accuracy', discrim_accuracy)\n",
    "            tf.summary.scalar('Generator_Loss', loss_gen)\n",
    "            \n",
    "        with tf.name_scope(\"perceptual_loss\") as scope:\n",
    "            tf.summary.scalar('VGG_Loss', loss_perceptual)\n",
    "        \n",
    "        with tf.name_scope(\"psnr_mse\") as scope:\n",
    "            tf.summary.scalar('PSNR', loss_psnr)\n",
    "            tf.summary.scalar('MSE', loss_mse)\n",
    "            tf.summary.scalar('SSIM', loss_ssim)\n",
    "            \n",
    "        with tf.name_scope(\"final_loss\") as scope:\n",
    "            tf.summary.scalar('Final_Loss', loss_final)\n",
    "            tf.summary.scalar('Adv_Loss', w_gan * loss_gen)\n",
    "            tf.summary.scalar('Pixel_Loss', w_pixel * loss_pixel)\n",
    "            tf.summary.scalar('Perceptual_Loss', w_perceptual * loss_perceptual)\n",
    "        \n",
    "        if(start_iter > 0):\n",
    "            print(\"Loading variables\")\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess, 'models/' + str(phone) + \"_\"  + init + '_iteration_' + str(start_iter) + \".ckpt\")\n",
    "            start_iter += 1\n",
    "            print(start_iter)\n",
    "            start_iter = int(start_iter)\n",
    "        else:\n",
    "            print('Initializing variables')\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "        print(\"Time elapsed: \" + str(time.time() - start))\n",
    "        print('Training network')  \n",
    "        \n",
    "        saver = tf.train.Saver(max_to_keep=3)\n",
    "        epoch_saver = tf.train.Saver()\n",
    "        gen_saver = tf.train.Saver(var_list=generator_vars, max_to_keep=1)\n",
    "        \n",
    "        train_loss_gen = 0.0\n",
    "        train_loss_disc = 0.0\n",
    "        train_acc_discrim = 0.0\n",
    "        crops_i = random.sample(range(TEST_SIZE), 5)\n",
    "        test_crops = test_data[crops_i, :]\n",
    "        test_gt = test_target[crops_i, :]\n",
    "\n",
    "        logs = open('models/' + phone + '.txt', \"w+\")\n",
    "        logs.close()\n",
    "        \n",
    "        merge = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter( os.path.join(os.getcwd(),'tensorboard/others/train_' + phone + '_' + model + model), tf.get_default_graph())\n",
    "        test_writer = tf.summary.FileWriter( os.path.join(os.getcwd(),'tensorboard/others/test_' + phone + '_' + model + model))\n",
    "        epoch_writer = tf.summary.FileWriter( os.path.join(os.getcwd(),'tensorboard/others/epoch_' + phone + '_' + model + model))\n",
    "        epoch_test_writer = tf.summary.FileWriter( os.path.join(os.getcwd(),'tensorboard/others/epoch_test_' + phone + '_' + model + model))\n",
    "        \n",
    "        run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "        \n",
    "        for i in range(start_iter, num_train_iters):\n",
    "            print(i)\n",
    "            iter_start = time.time()\n",
    "            print(\"Training \" + str((i + 1) * batch_size) + \"/\" + str(total_train_data))\n",
    "            \n",
    "            be = (num_train_batches - 1) * batch_size\n",
    "            en = num_train_batches * batch_size\n",
    "            idx_train = range(be,en)\n",
    "            lq_images = train_data[idx_train]\n",
    "            hq_images = train_target[idx_train]\n",
    "            \n",
    "            num_train_batches -= 1\n",
    "            \n",
    "            for j in range(g_iters):\n",
    "                # train generator\n",
    "                [summary, loss_temp, acc, temp] = sess.run([merge, loss_final, loss_gen, train_step_gen],\n",
    "                                                feed_dict={lq_: lq_images, hq_: hq_images, is_train: 1}, options = run_options)\n",
    "                \n",
    "                train_loss_gen += loss_temp / (load_step * g_iters)\n",
    "            for j in range(d_iters):\n",
    "                # train discriminator\n",
    "                [summary, accuracy_temp, loss_temp, temp] = sess.run([merge, discrim_accuracy, loss_discrim, train_step_disc],\n",
    "                                                feed_dict={lq_:lq_images, hq_:hq_images, is_train: 1}, options = run_options)\n",
    "                train_loss_disc += loss_temp / (load_step * d_iters)\n",
    "                train_acc_discrim += accuracy_temp / (load_step * d_iters)\n",
    "            train_writer.add_summary(summary, i)\n",
    "            if (i % iters_per_epoch == 0 or i == num_train_iters-1):\n",
    "                epoch_writer.add_summary(summary, math.ceil(i / iters_per_epoch))\n",
    "                \n",
    "            print(\"Iteration Time Elapsed: \" + str(time.time() - iter_start))\n",
    "                \n",
    "            if((i + 1) % load_step == 0 or i % iters_per_epoch == 0 or i == num_train_iters-1):\n",
    "\n",
    "                # test generator and discriminator CNNs\n",
    "                test_losses_gen = np.zeros((1, 9))\n",
    "                test_accuracy_disc = 0.0\n",
    "\n",
    "                for j in range(num_test_batches):\n",
    "\n",
    "                    be = j * batch_size\n",
    "                    en = (j+1) * batch_size\n",
    "\n",
    "                    lq_images = test_data[be:en]\n",
    "                    hq_images = test_target[be:en]\n",
    "\n",
    "                    [summary, accuracy_disc, losses] = sess.run([merge, discrim_accuracy, \\\n",
    "                                 [loss_final, loss_gen, loss_pixel, loss_perceptual, loss_discrim, accuracy_real, accuracy_fake, loss_psnr, loss_ssim]], \\\n",
    "                                    feed_dict={lq_: lq_images, hq_: hq_images, is_train: 0})\n",
    "                    test_writer.add_summary(summary, i)\n",
    "                    \n",
    "                    \n",
    "                    if (i % iters_per_epoch == 0 or i == num_train_iters-1):\n",
    "                        epoch_test_writer.add_summary(summary, math.ceil(i / iters_per_epoch))\n",
    "\n",
    "                    test_losses_gen += np.asarray(losses) / num_test_batches\n",
    "                    test_accuracy_disc += accuracy_disc / num_test_batches\n",
    "\n",
    "                logs_disc = \"Iteration %d, %s | discriminator accuracy | train: %.4g, test: %.4g | discriminator loss | train: %.4g test: %.4g real: %.4g fake: %.4g\" % \\\n",
    "                  (i, phone, train_acc_discrim, test_accuracy_disc, train_loss_disc, test_losses_gen[0][4], test_losses_gen[0][5], test_losses_gen[0][6])\n",
    "                logs_gen = \"generator losses | train: %.4g, test: %.4g | gen: %.4g, pixel: %.4g vgg: %.4g PSNR: %.4g SSIM: %.4g\\n\" % \\\n",
    "                  (train_loss_gen, test_losses_gen[0][0], test_losses_gen[0][1], test_losses_gen[0][2], test_losses_gen[0][3], test_losses_gen[0][7], test_losses_gen[0][8])\n",
    "                print(logs_disc)\n",
    "                print(logs_gen)\n",
    "\n",
    "                # save the results to log file\n",
    "\n",
    "                logs = open('models/' + phone + model + '.txt', \"a\")\n",
    "                \n",
    "                if(i == 0):\n",
    "                    logs.write(\"\\nGAN loss: \" + str(gan))\n",
    "                    logs.write(\"\\nTrain Data: \" + str(num_train_data))\n",
    "                    logs.write(\"\\nBatch Size: \" + str(batch_size))\n",
    "                    logs.write(\"\\nNumber of Epochs:\" + str(num_train_iters / iters_per_epoch))\n",
    "                    logs.write(\"\\nIterations: \" + str(num_train_iters))\n",
    "                    logs.write(\"\\nIterations per Epoch: \" + str(iters_per_epoch))\n",
    "                    logs.write(\"\\nTrain Size: \" + str(train_size))\n",
    "                    logs.write(\"\\nTest Data Size: \" + str(test_size))\n",
    "                    logs.write(\"\\nLoad Iteration: \" + str(load_step))\n",
    "                    logs.write(\"\\nLearning Rate (Gen): \" + str(learning_rate_gen))\n",
    "                    logs.write(\"\\nLearning Rate (Disc): \" + str(learning_rate_disc))\n",
    "                    logs.write(\"\\nStart Iteration: \" + str(start_iter))\n",
    "                    logs.write(\"\\nInitialization: \" + init)   \n",
    "                    logs.write('\\n')\n",
    "                    logs.write('\\n')\n",
    "                    \n",
    "                gen_hq_crops = sess.run(gen_hq, feed_dict={lq_: test_crops, hq_: hq_images, is_train: 0}, options = run_options)\n",
    "                if ((i + 1) % load_step == 0 or i == num_train_iters-1):\n",
    "                    logs.write(logs_gen)\n",
    "                    logs.write(logs_disc)\n",
    "                    logs.write('\\n')\n",
    "                \n",
    "                logs.close()\n",
    "                idx = 0\n",
    "                for crop in gen_hq_crops:\n",
    "                    crop = (crop + 1) / 2\n",
    "                    before_after = np.hstack((np.reshape(test_crops[idx], [PATCH_HEIGHT, PATCH_WIDTH, 3]), crop, (np.reshape(test_gt[idx], [PATCH_HEIGHT, PATCH_WIDTH, 3]))))\n",
    "                    plt.imsave('validation_results/' + str(phone) + model + \"_\" + str(idx) + '_iteration_' + str(i) + '.jpg', before_after)\n",
    "                    idx += 1\n",
    "                \n",
    "                if((i + 1) % load_step == 0): \n",
    "                    train_loss_gen = 0.0\n",
    "                    train_loss_disc = 0.0\n",
    "                    train_acc_discrim = 0.0\n",
    "\n",
    "                # save the model that corresponds to the current iteration\n",
    "                if(i % iters_per_epoch == 0 and i != 0):\n",
    "                    epoch_saver.save(sess, 'models/' + str(phone) + \"_\"  + model + '_epoch_' + str(int(math.floor(i / iters_per_epoch))) + '.ckpt', write_meta_graph=False)\n",
    "                if((i + 1) % load_step == 0 or i == num_train_iters-1):\n",
    "                    saver.save(sess, 'models/' + str(phone) + \"_\"  + model + '_iteration_' + str(i) + '.ckpt', write_meta_graph=False)\n",
    "                print(\"Loading new batch...\")\n",
    "                \n",
    "            # reload a next batch of training data\n",
    "            if(reload and num_train_batches == 0):\n",
    "                print(\"Loading \" + str(i))\n",
    "                del train_data\n",
    "                del train_target\n",
    "                print((data_idx % load_per_epoch) * train_size)\n",
    "                print(((data_idx % load_per_epoch) + 1) * train_size)\n",
    "                train_data, train_target, reload = load_train_data(phone, dataset_dir, train_size, PATCH_SIZE, PATCH_WIDTH, target, data_idx % load_per_epoch, train_data_size=num_train_data)\n",
    "                data_idx += 1\n",
    "            \n",
    "            if(num_train_batches == 0):\n",
    "                num_train_batches = int(math.floor(train_data.shape[0] / batch_size))\n",
    "                print(num_train_batches)\n",
    "                indices = np.arange(train_data.shape[0])\n",
    "                np.random.shuffle(indices)\n",
    "\n",
    "                train_data = train_data[indices]\n",
    "                train_target = train_target[indices]\n",
    "                \n",
    "                \n",
    "            print(\"New Batch Loaded...\")\n",
    "            print(\"Time Elapsed: \" + str(time.time() - start))\n",
    "                        \n",
    "        print(\"Total Time Elapsed: \" + str(time.time() - start))\n",
    "        \n",
    "        logs = open('models/' + phone + model + '.txt', \"a\")\n",
    "        logs.write(\"\\n\\nTotal Time Elapsed: \" + str(time.time() - start))\n",
    "        logs.write('\\n')\n",
    "        logs.close()\n",
    "\n",
    "        train_writer.close()\n",
    "        test_writer.close()\n",
    "        epoch_writer.close()\n",
    "        epoch_test_writer.close()\n",
    "    \n",
    "                \n",
    "                    \n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
